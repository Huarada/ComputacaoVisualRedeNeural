Neural Net 3D Parallel

VisualizaÃ§Ã£o em OpenGL de redes neurais com camadas paralelas (estÃ¡gios e branches).
Permite carregar ativaÃ§Ãµes a partir de um arquivo .txt e exibir os neurÃ´nios e conexÃµes em 3D, com cores variando conforme intensidade.

ğŸ“¦ Requisitos

Windows + MinGW (ou WSL/Linux equivalente)

Bibliotecas:

GLFW3
 (dll + headers + lib)

GLAD
 (cÃ³digo C jÃ¡ incluso em src/glad.c)

OpenGL 3.3+ (placa de vÃ­deo compatÃ­vel)

Certifique-se de ter o arquivo glfw3.dll no mesmo diretÃ³rio do executÃ¡vel.

ğŸ”¨ CompilaÃ§Ã£o

Dentro da pasta do projeto, rode no terminal:

g++ -std=c++17 -O2 -I include src\glad.c neural_net_3d_parallel.cpp -L lib -lglfw3dll -lopengl32 -lgdi32 -luser32 -lkernel32 -o neural3d.exe


-I include â†’ pasta onde estÃ£o glad.h e GLFW/glfw3.h

-L lib â†’ pasta onde estÃ¡ glfw3dll.lib

-lopengl32 -lgdi32 -luser32 -lkernel32 â†’ dependÃªncias do Windows/OpenGL

Se jÃ¡ tiver o executÃ¡vel (neural3d.exe), pode pular esta etapa.

ğŸ“ Input de ativaÃ§Ãµes

As ativaÃ§Ãµes devem estar no arquivo ativacoes.txt.
O formato aceito Ã© um array de arrays, por exemplo:

[[0,1,2], [[4,2,1],[1,2,4]]]


Cada camada (stage) Ã© um array.

Dentro de um estÃ¡gio podem existir branches (sub-arrays).

Cada nÃºmero representa a ativaÃ§Ã£o/neuron count.

Valores negativos sÃ£o convertidos para 0.

â–¶ï¸ Para Compilar:
```bash
g++ -std=c++17 -O2 -I include src\glad.c .\neural_net_3d_parallel.cpp -L lib -lglfw3dll -lopengl32 -lgdi32 -luser32 -lkernel32 -o neural3d.exe
```


â–¶ï¸ ExecuÃ§Ã£o

Para rodar lendo o arquivo:

neural3d.exe ativacoes.txt
ou em windows:
```bash
.\neural3d.exe .\ativacoes.txt
```


Ou, via stdin (pipe):

type ativacoes.txt | neural3d.exe


Se nÃ£o fornecer input, serÃ¡ usado o default:

[[0,1,2], [[4,2,1],[1,2,4]]]

ğŸ¨ Controles

Mouse esquerdo + arrastar â†’ rotaciona a cÃ¢mera em torno da rede

Scroll (dependendo da versÃ£o) â†’ zoom (ajustÃ¡vel no cÃ³digo via gRadius)

Esferas = neurÃ´nios

Linhas = conexÃµes entre estÃ¡gios

Cores:

0 = cinza

1 = azul

2 = verde

3 = amarelo

4 = laranja

5+ = vermelho

neural_net_3d_parallel

ğŸš€ Exemplo prÃ¡tico

Crie ativacoes.txt:

[[1,2,3], [[0,1],[2,2]], [4,1]]


Estrutura geral

O input no ativacoes.txt Ã© um array de estÃ¡gios:

[ stage0, stage1, stage2, ... ]


Cada stage pode ser:

Array de nÃºmeros â†’ significa um Ãºnico branch (sequÃªncia linear de neurÃ´nios).
Exemplo:

[3,2,1]


â†’ Um branch Ãºnico com 3 neurÃ´nios, depois 2, depois 1.

Array de arrays de nÃºmeros â†’ significa branches em paralelo dentro do mesmo estÃ¡gio.
Exemplo:

[[3,1], [2,2]]


â†’ Dois branches paralelos:

Branch 0: 3 neurÃ´nios seguidos de 1

Branch 1: 2 neurÃ´nios seguidos de 2

ğŸ“Œ Exemplo do seu caso

Entrada:

[3, [3,1]]

InterpretaÃ§Ã£o

Stage 0 â†’ [3]
â†’ Uma camada Ãºnica com 3 neurÃ´nios em sÃ©rie.

Stage 1 â†’ [3,1] mas dentro de colchetes adicionais â†’ significa um branch paralelo.
â†’ Um branch com:

camada com 3 neurÃ´nios

seguida de camada com 1 neurÃ´nio

Estrutura resultante

Linha principal (em sÃ©rie): 3 neurÃ´nios

Em paralelo, logo depois, surge um branch lateral com 3 neurÃ´nios â†’ 1 neurÃ´nio.

Visualmente, o cÃ³digo vai colocar:

No eixo X â†’ os estÃ¡gios (stage0, stage1, â€¦)

No eixo Y â†’ os neurÃ´nios de cada camada

No eixo Z â†’ cada branch paralelo dentro do mesmo estÃ¡gio

neural_net_3d_parallel

ğŸ–¼ Visual mental
Stage 0 (linear)     Stage 1 (paralelo)
      â—â—â—             Branch0: â—â—â— â†’ â—
                        (3)      (1)


As conexÃµes (linhas) ligam todos os neurÃ´nios de Stage0 para todos os neurÃ´nios de cada branch do Stage1.

ğŸ§ª Teste prÃ¡tico

Crie um ativacoes.txt com:

[[3], [3,1]]


E rode:

neural3d.exe ativacoes.txt


VocÃª verÃ¡:

Primeiro bloco (X=-6) â†’ 3 neurÃ´nios

Segundo bloco (X=0) â†’ dois nÃ­veis em um branch paralelo: 3 neurÃ´nios â†’ 1 neurÃ´nio.



Rode:

neural3d.exe ativacoes.txt


Uma janela abrirÃ¡ mostrando a rede neural 3D com cores e conexÃµes.

Esses arquivos sÃ£o temporÃ¡rios e utilizados apenas para compor o JSON unificado.

---

# ğŸ§  Uso do Extrator

O **Extrator** Ã© um conjunto de ferramentas para **monitorar, registrar e visualizar** as ativaÃ§Ãµes e gradientes de redes neurais durante o treinamento.  
Ele permite compreender o comportamento interno de cada camada â€” convolucional e densa â€” gerando arquivos JSON detalhados e grÃ¡ficos que documentam a evoluÃ§Ã£o do modelo.

---

## âš™ï¸ Demo ExecutÃ¡vel

HÃ¡ uma demo executÃ¡vel no arquivo **`demo_train_catsdogs_unified.py`**.  
Essa demo realiza a **extraÃ§Ã£o das informaÃ§Ãµes** durante o treinamento e salva os dados em um arquivo **JSON**.

O JSON resultante Ã© nomeado como: unified_epoch_X_demo_unified_final.json

onde **X** representa o nÃºmero da Ã©poca salva.  

AlÃ©m disso, tambÃ©m sÃ£o gerados arquivos auxiliares: dense_epoch_X_demo_unified_final.json 

Esses arquivos sÃ£o temporÃ¡rios e utilizados apenas para compor o JSON unificado.

---

## ğŸ—‚ï¸ Estrutura do JSON

### **meta**
ContÃ©m informaÃ§Ãµes gerais da execuÃ§Ã£o:
- `epoch`: Ã©poca Ã  qual os dados se referem  
- `timestamp`: data e hora da execuÃ§Ã£o  
- `run_id`: identificaÃ§Ã£o Ãºnica da execuÃ§Ã£o  

### **conv**
Dados referentes Ã s camadas convolucionais:
- `epoch`: Ã©poca correspondente  
- `layers`: lista de camadas convolucionais monitoradas  

Cada camada (ex: `conv1`) contÃ©m:
- `H`: altura do Grad-Map  
- `W`: largura do Grad-Map  
- `count`: nÃºmero de amostras utilizadas para gerar o Grad-Map  
- `map`: tensor com os dados do Grad-Map, utilizado para visualizar os padrÃµes aprendidos pela camada  
- `acts-meta`: metadados das ativaÃ§Ãµes  
  - `H`: altura do mapa de features  
  - `W`: largura do mapa de features  
  - `channels`: nÃºmero de canais da camada  
  - `imgs`: nÃºmero de imagens de referÃªncia usadas para extrair as ativaÃ§Ãµes  
- `acts`: vetor contendo todas as ativaÃ§Ãµes para as entradas de referÃªncia fixadas  

### **dense**
Dados referentes Ã s camadas densas:
- **meta**: informaÃ§Ãµes gerais  
  - `epoch`: Ã©poca correspondente  
  - `timestamp`: data e hora da execuÃ§Ã£o  
  - `run_id`: identificaÃ§Ã£o da execuÃ§Ã£o  
  - `total_examples`: nÃºmero de amostras utilizadas para extrair o *Gradient Ã— Activation*  

- **layers**: lista de camadas densas monitoradas  

Cada camada (ex: `fc1`) contÃ©m:
- `in_features`: dimensÃ£o da entrada  
- `out_features`: dimensÃ£o da saÃ­da (ou nÃºmero de neurÃ´nios)  
- `ref_inputs`: lista de vetores de entrada da camada para as amostras de referÃªncia fixadas  
- `ref_acts`: ativaÃ§Ãµes correspondentes Ã s entradas de referÃªncia  
- `heatmap`: vetor contendo o *Gradient Ã— Activation*, que representa a forÃ§a de cada ligaÃ§Ã£o entre neurÃ´nios.  
  Para obter a relevÃ¢ncia individual de cada neurÃ´nio, deve-se somar e normalizar esses valores.  

### **metrics**
EstatÃ­sticas do treinamento atÃ© a Ã©poca atual:
- `acc_per_epoch`: acurÃ¡cias por Ã©poca registradas anteriormente
- `acc_last`: acurÃ¡cia da Ãºltima Ã©poca registrada  
- `refs_orig_png_grid`: mosaico contendo todas as imagens de referÃªncia utilizadas na rede  
- `ref_indices`: Ã­ndices do *loader* referentes Ã s imagens fixadas como referÃªncia  

---

## ğŸ“Š SaÃ­das Adicionais

AlÃ©m dos arquivos JSON por Ã©poca, a demo tambÃ©m gera:
- **`acc_plot_epoch_X.png`** â†’ grÃ¡fico da evoluÃ§Ã£o da acurÃ¡cia atÃ© a Ã©poca X.  
  A geraÃ§Ã£o desses grÃ¡ficos Ã© feita pela funÃ§Ã£o **`_plot_acc_then_png()`**.

- **`ativacao.txt`** â†’ arquivo utilizado para a **visualizaÃ§Ã£o 3D da arquitetura da rede**.  
  O cÃ³digo responsÃ¡vel por gerar este arquivo encontra-se em **`gen_architecture.py`**.

- **`refs_orig_i` â†’ i-Ã©sima imagem de referÃªncia fixada do loader.

---

## ğŸ–¥ï¸ Visualizadores

TrÃªs programas adicionais permitem a visualizaÃ§Ã£o dos dados contidos nos JSONs:

1. **`visualizador_de_acts_maps_tkinter_matplotlib.py`**  
   â†’ Exibe as ativaÃ§Ãµes das camadas convolucionais como imagens.

2. **`visualizador_de_grad_maps_tkinter_matplotlib.py`**  
   â†’ Exibe os *Layer-Maps* das camadas convolucionais.

3. **`visualizador_de_neuronios_tkinter_matplotlib.py`**  
   â†’ Exibe as ativaÃ§Ãµes e os *Gradient Ã— Activation* das camadas densas.

---

## ğŸ§© ConfiguraÃ§Ã£o de uma Nova Rede

Para realizar a extraÃ§Ã£o de dados durante o treinamento com outra rede, basta seguir o exemplo contido em **`demo_train_catsdogs_unified.py`**.  

Caso deseje reproduzir exatamente o procedimento da funÃ§Ã£o `main()`, siga estes passos:
1. Crie uma classe de modelo semelhante Ã  **`SmallCNN`**.  
2. Implemente uma funÃ§Ã£o de *loader* de dataset, semelhante Ã  **`get_catsdogs_loader()`**.

Essas duas partes garantem a compatibilidade com o pipeline de extraÃ§Ã£o e salvamento em JSON.

---
