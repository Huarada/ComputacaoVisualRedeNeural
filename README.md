Neural Net 3D Parallel

Visualiza√ß√£o em OpenGL de redes neurais com camadas paralelas (est√°gios e branches).
Permite carregar ativa√ß√µes a partir de um arquivo .txt e exibir os neur√¥nios e conex√µes em 3D, com cores variando conforme intensidade.

üì¶ Requisitos

Windows + MinGW (ou WSL/Linux equivalente)

Bibliotecas:

GLFW3
 (dll + headers + lib)

GLAD
 (c√≥digo C j√° incluso em src/glad.c)

OpenGL 3.3+ (placa de v√≠deo compat√≠vel)

Certifique-se de ter o arquivo glfw3.dll no mesmo diret√≥rio do execut√°vel.

üî® Compila√ß√£o

Dentro da pasta do projeto, rode no terminal:

g++ -std=c++17 -O2 -I include src\glad.c neural_net_3d_parallel.cpp -L lib -lglfw3dll -lopengl32 -lgdi32 -luser32 -lkernel32 -o neural3d.exe


-I include ‚Üí pasta onde est√£o glad.h e GLFW/glfw3.h

-L lib ‚Üí pasta onde est√° glfw3dll.lib

-lopengl32 -lgdi32 -luser32 -lkernel32 ‚Üí depend√™ncias do Windows/OpenGL

Se j√° tiver o execut√°vel (neural3d.exe), pode pular esta etapa.

üìù Input de ativa√ß√µes

As ativa√ß√µes devem estar no arquivo ativacoes.txt.
O formato aceito √© um array de arrays, por exemplo:

[[0,1,2], [[4,2,1],[1,2,4]]]


Cada camada (stage) √© um array.

Dentro de um est√°gio podem existir branches (sub-arrays).

Cada n√∫mero representa a ativa√ß√£o/neuron count.

Valores negativos s√£o convertidos para 0.

‚ñ∂Ô∏è Para Compilar:
```bash
g++ -std=c++17 -O2 -I include src\glad.c .\neural_net_3d_conv_refactored.cpp -L lib -lglfw3dll -lopengl32 -lgdi32 -luser32 -lkernel32 -o neural3d.exe
```


‚ñ∂Ô∏è Execu√ß√£o

Para rodar lendo o arquivo:

neural3d.exe ativacoes.txt
ou em windows:
```bash
.\neural3d.exe .\ativacoes.txt
```


Ou, via stdin (pipe):

type ativacoes.txt | neural3d.exe


Se n√£o fornecer input, ser√° usado o default:

[[0,1,2], [[4,2,1],[1,2,4]]]

üé® Controles

Mouse esquerdo + arrastar ‚Üí rotaciona a c√¢mera em torno da rede

Scroll (dependendo da vers√£o) ‚Üí zoom (ajust√°vel no c√≥digo via gRadius)

Esferas = neur√¥nios

Linhas = conex√µes entre est√°gios

Cores:

0 = cinza

1 = azul

2 = verde

3 = amarelo

4 = laranja

5+ = vermelho

neural_net_3d_parallel

üöÄ Exemplo pr√°tico

Crie ativacoes.txt:

[[1,2,3], [[0,1],[2,2]], [4,1]]


Estrutura geral

O input no ativacoes.txt √© um array de est√°gios:

[ stage0, stage1, stage2, ... ]


Cada stage pode ser:

Array de n√∫meros ‚Üí significa um √∫nico branch (sequ√™ncia linear de neur√¥nios).
Exemplo:

[3,2,1]


‚Üí Um branch √∫nico com 3 neur√¥nios, depois 2, depois 1.

Array de arrays de n√∫meros ‚Üí significa branches em paralelo dentro do mesmo est√°gio.
Exemplo:

[[3,1], [2,2]]


‚Üí Dois branches paralelos:

Branch 0: 3 neur√¥nios seguidos de 1

Branch 1: 2 neur√¥nios seguidos de 2

üìå Exemplo do seu caso

Entrada:

[3, [3,1]]

Interpreta√ß√£o

Stage 0 ‚Üí [3]
‚Üí Uma camada √∫nica com 3 neur√¥nios em s√©rie.

Stage 1 ‚Üí [3,1] mas dentro de colchetes adicionais ‚Üí significa um branch paralelo.
‚Üí Um branch com:

camada com 3 neur√¥nios

seguida de camada com 1 neur√¥nio

Estrutura resultante

Linha principal (em s√©rie): 3 neur√¥nios

Em paralelo, logo depois, surge um branch lateral com 3 neur√¥nios ‚Üí 1 neur√¥nio.

Visualmente, o c√≥digo vai colocar:

No eixo X ‚Üí os est√°gios (stage0, stage1, ‚Ä¶)

No eixo Y ‚Üí os neur√¥nios de cada camada

No eixo Z ‚Üí cada branch paralelo dentro do mesmo est√°gio

neural_net_3d_parallel

üñº Visual mental
Stage 0 (linear)     Stage 1 (paralelo)
      ‚óè‚óè‚óè             Branch0: ‚óè‚óè‚óè ‚Üí ‚óè
                        (3)      (1)


As conex√µes (linhas) ligam todos os neur√¥nios de Stage0 para todos os neur√¥nios de cada branch do Stage1.

üß™ Teste pr√°tico

Crie um ativacoes.txt com:

[[3], [3,1]]


E rode:

neural3d.exe ativacoes.txt


Voc√™ ver√°:

Primeiro bloco (X=-6) ‚Üí 3 neur√¥nios

Segundo bloco (X=0) ‚Üí dois n√≠veis em um branch paralelo: 3 neur√¥nios ‚Üí 1 neur√¥nio.



Rode:

neural3d.exe ativacoes.txt


Uma janela abrir√° mostrando a rede neural 3D com cores e conex√µes.

Esses arquivos s√£o tempor√°rios e utilizados apenas para compor o JSON unificado.
NOTA: O que cada parte do c√≥digo faz

O projeto √© single-file mas fortemente modularizado por classes, com nomes longos e coment√°rios:

1 namespace Math

  Fun√ß√µes matem√°ticas expl√≠citas (identidade, perspective, lookAt, normaliza√ß√£o, produto vetorial, etc.).
  Importante para depura√ß√£o: todas as matrizes/operadores t√™m nomes que indicam inten√ß√£o (ex.: MakeLookAtMatrix, MultiplyMat4).

2 Shaders (kLineVS/kLineFS e kLitVS/kLitFS)

  Line shader: desenha as conex√µes entre camadas.
  
  Lit shader: Phong ‚Äúbarato‚Äù para ilumina√ß√£o difusa + rim light, usado em esferas (neur√¥nios) e pain√©is (folhas de conv).

3 Geometry builders

  BuildNeuronSphereMesh(...)
  Gera esfera (pos + normal) para cada neur√¥nio.
  
  BuildConvPanelCubeMesh(...)
  Gera um cubo unit√°rio. Cada ‚Äúfolha‚Äù da CONV √© um cubo escalado (painel fino).

4 Parser de entrada (AST)

  ParseNode(...) + auxiliares (ParseNumberToken, ParseConvToken etc.)
  Interpretam o texto do arquivo na mesma gram√°tica do c√≥digo original.

5 Sem√¢ntica do modelo (LayerUnit, Stage, Branch)
   
   LayerUnit descreve um elemento l√≥gico da rede:
   
   kNeuron + neuronCount (apenas para colorir/legenda pedag√≥gica)
   
   kConvolution + A,B,C (dimens√µes AxBxC)
   
   Stage √© um vetor de Branch.
   
   Branch √© um vetor de LayerUnit.
   
   Esta estrutura preserva a ideia de m√∫ltiplos ramos por est√°gio.

6 Visuals (dados prontos para render)

  NeuronLayerVisual
  Guarda inst√¢ncias: centro, raio e ‚Äún√≠vel‚Äù para cor.
  
  ConvLayerVisual
  Guarda blocos {A,B,C} convertidos em dimens√µes no mundo (width/height/depth) e par√¢metros visuais:
  
  panelSpacingMultiplier ‚Üí espa√ßo ‚Äúem branco‚Äù entre as folhas (sem alterar a grossura).
  
  baseColorRGB ‚Üí cor base do gradiente de profundidade.

7 CnnModelLayout

  Cora√ß√£o do pipeline de dados:
  
  LoadInputAndBuildLayout(argc, argv)
  
  L√™ argv[1] (ou STDIN)
  
  Faz o parse para AST ‚Üí parsedStages
  
  Constr√≥i visuals + √¢ncoras + linhas.
  
  BuildVisualLayersAndComputeBounds()
  
  Normaliza dimens√µes com base nos m√°ximos {A,B,C} do modelo.
  
  Calcula a posi√ß√£o (X/Y/Z) de cada inst√¢ncia:
  
  Esferas (neur√¥nios) ‚Üí raio padr√£o (configur√°vel).
  
  Blocos conv ‚Üí largura/altura/profundidade proporcionais aos seus A/B/C.
  
  Gera √¢ncoras para conex√µes (lado direito/esquerdo), respeitando o meio-tamanho em X:
  
  Neur√¥nios usam o raio como halfWidthX.
  
  Convs usam metade da largura.
  
  Constr√≥i connectionLineVertices (lista xyz intercalada) ligando todo est√°gio s ‚Üí s+1.
  
  Getter p√∫blico sugerido:
  
  GetConnectionLineVertices() retorna as linhas para o renderer.
  
  Par√¢metros visuais f√°ceis de ajustar (comentados no c√≥digo):
  
  Raio do neur√¥nio: kNeuronRadius
  
  Espa√ßamento vertical (entre linhas): kRowSpacingY
  
  Espa√ßamento entre ramos (Z): kBranchSpacingZ
  
  Espa√ßamento entre folhas da CONV: ConvLayerVisual::panelSpacingMultiplier

8 SceneRenderer

 Tudo de OpenGL + c√¢mera:

 Cria√ß√£o de janela/GL, compila√ß√£o e link dos shaders.

 Cria√ß√£o dos VAOs/VBOs para esfera, cubo e linhas.
 
 C√¢mera orbital com callbacks (mouse/scroll).
 
 UploadConnectionLines(layout)
 Sobe connectionLineVertices para GPU (VBO).

 RenderFrame(...)
 
 Calcula ViewProj, desenha linhas primeiro (shader de linhas).
 
 Desenha neur√¥nios (esferas) com escala = raio.
 
 Desenha camadas CONV como pain√©is (folhas) com espessura fina + gap configur√°vel.
 
 Hotkeys (1/2/3/0/Esc) j√° tratados.
 
 IMPORTANTE: Ajustes comuns (pontos ‚Äúperguntados com frequ√™ncia‚Äù)
 
 Tamanho das esferas (neur√¥nios)
 Procure por kNeuronRadius em CnnModelLayout::BuildVisualLayersAndComputeBounds().
 A escala da malha da esfera usa diretamente esse raio.
 
 Afastar as folhas da conv (mais espa√ßo em branco)
 Modifique ConvLayerVisual::panelSpacingMultiplier.
 Isso n√£o altera a ‚Äúgrossura‚Äù (thickness) da folha, s√≥ a dist√¢ncia entre elas.
 
 Largura/altura/profundidade do bloco conv
 S√£o proporcionais a {A,B,C} normalizados pelos m√°ximos do modelo, limitados por:
 
 kWorldMaxWidth, kWorldMaxHeight, kWorldMaxDepth.
 
 Conex√µes n√£o aparecem?
 Verifique se UploadConnectionLines(layout) √© chamado ap√≥s criar o contexto OpenGL (ap√≥s CreateWindowAndInitializeGlContext()), e se seu input tem pelo menos 2 est√°gios.

                                                FIM DO TRECHO SOBRE A MODELAGEM 3D 

# üß† Uso do Extrator

O **Extrator** √© um conjunto de ferramentas para **monitorar, registrar e visualizar** as ativa√ß√µes e gradientes de redes neurais durante o treinamento.  
Ele permite compreender o comportamento interno de cada camada ‚Äî convolucional e densa ‚Äî gerando arquivos JSON detalhados e gr√°ficos que documentam a evolu√ß√£o do modelo.

---

## ‚öôÔ∏è Demo Execut√°vel

H√° uma demo execut√°vel no arquivo **`demo_train_catsdogs_unified.py`**.  
Essa demo realiza a **extra√ß√£o das informa√ß√µes** durante o treinamento e salva os dados em um arquivo **JSON**.

O JSON resultante √© nomeado como: unified_epoch_X_demo_unified_final.json

onde **X** representa o n√∫mero da √©poca salva.  

Al√©m disso, tamb√©m s√£o gerados arquivos auxiliares: dense_epoch_X_demo_unified_final.json 

Esses arquivos s√£o tempor√°rios e utilizados apenas para compor o JSON unificado.

---

## üóÇÔ∏è Estrutura do JSON

### **meta**
Cont√©m informa√ß√µes gerais da execu√ß√£o:
- `epoch`: √©poca √† qual os dados se referem  
- `timestamp`: data e hora da execu√ß√£o  
- `run_id`: identifica√ß√£o √∫nica da execu√ß√£o  

### **conv**
Dados referentes √†s camadas convolucionais:
- `epoch`: √©poca correspondente  
- `layers`: lista de camadas convolucionais monitoradas  

Cada camada (ex: `conv1`) cont√©m:
- `H`: altura do Grad-Map  
- `W`: largura do Grad-Map  
- `count`: n√∫mero de amostras utilizadas para gerar o Grad-Map  
- `map`: tensor com os dados do Grad-Map, utilizado para visualizar os padr√µes aprendidos pela camada  
- `acts-meta`: metadados das ativa√ß√µes  
  - `H`: altura do mapa de features  
  - `W`: largura do mapa de features  
  - `channels`: n√∫mero de canais da camada  
  - `imgs`: n√∫mero de imagens de refer√™ncia usadas para extrair as ativa√ß√µes  
- `acts`: vetor contendo todas as ativa√ß√µes para as entradas de refer√™ncia fixadas  

### **dense**
Dados referentes √†s camadas densas:
- **meta**: informa√ß√µes gerais  
  - `epoch`: √©poca correspondente  
  - `timestamp`: data e hora da execu√ß√£o  
  - `run_id`: identifica√ß√£o da execu√ß√£o  
  - `total_examples`: n√∫mero de amostras utilizadas para extrair o *Gradient √ó Activation*  

- **layers**: lista de camadas densas monitoradas  

Cada camada (ex: `fc1`) cont√©m:
- `in_features`: dimens√£o da entrada  
- `out_features`: dimens√£o da sa√≠da (ou n√∫mero de neur√¥nios)  
- `ref_inputs`: lista de vetores de entrada da camada para as amostras de refer√™ncia fixadas  
- `ref_acts`: ativa√ß√µes correspondentes √†s entradas de refer√™ncia  
- `heatmap`: vetor contendo o *Gradient √ó Activation*, que representa a for√ßa de cada liga√ß√£o entre neur√¥nios.  
  Para obter a relev√¢ncia individual de cada neur√¥nio, deve-se somar e normalizar esses valores.  

### **metrics**
Estat√≠sticas do treinamento at√© a √©poca atual:
- `acc_per_epoch`: acur√°cias por √©poca registradas anteriormente
- `acc_last`: acur√°cia da √∫ltima √©poca registrada  
- `refs_orig_png_grid`: mosaico contendo todas as imagens de refer√™ncia utilizadas na rede  
- `ref_indices`: √≠ndices do *loader* referentes √†s imagens fixadas como refer√™ncia  

---

## üìä Sa√≠das Adicionais

Al√©m dos arquivos JSON por √©poca, a demo tamb√©m gera:
- **`acc_plot_epoch_X.png`** ‚Üí gr√°fico da evolu√ß√£o da acur√°cia at√© a √©poca X.  
  A gera√ß√£o desses gr√°ficos √© feita pela fun√ß√£o **`_plot_acc_then_png()`**.

- **`ativacao.txt`** ‚Üí arquivo utilizado para a **visualiza√ß√£o 3D da arquitetura da rede**.  
  O c√≥digo respons√°vel por gerar este arquivo encontra-se em **`gen_architecture.py`**.

- **`refs_orig_i.png`** ‚Üí i-√©sima imagem de refer√™ncia fixada do loader.

---

## üñ•Ô∏è Visualizadores

Tr√™s programas adicionais permitem a visualiza√ß√£o dos dados contidos nos JSONs:

1. **`visualizador_de_acts_maps_tkinter_matplotlib.py`**  
   ‚Üí Exibe as ativa√ß√µes das camadas convolucionais como imagens.

2. **`visualizador_de_grad_maps_tkinter_matplotlib.py`**  
   ‚Üí Exibe os *Layer-Maps* das camadas convolucionais.

3. **`visualizador_de_neuronios_tkinter_matplotlib.py`**  
   ‚Üí Exibe as ativa√ß√µes e os *Gradient √ó Activation* das camadas densas.

---

## üß© Configura√ß√£o de uma Nova Rede

Para realizar a extra√ß√£o de dados durante o treinamento com outra rede, basta seguir o exemplo contido em **`demo_train_catsdogs_unified.py`**.  

Caso deseje reproduzir exatamente o procedimento da fun√ß√£o `main()`, siga estes passos:
1. Crie uma classe de modelo semelhante √† **`SmallCNN`**.  
2. Implemente uma fun√ß√£o de *loader* de dataset, semelhante √† **`get_catsdogs_loader()`**.

Essas duas partes garantem a compatibilidade com o pipeline de extra√ß√£o e salvamento em JSON.

---
